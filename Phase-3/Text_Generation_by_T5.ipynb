{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Generation_by_T5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozvI1rMWftD6"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install SentencePiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAJodpP5fy_J"
      },
      "source": [
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "from nltk.translate.bleu_score import SmoothingFunction, corpus_bleu, sentence_bleu\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDG2z-c9fzDs"
      },
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-base')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIF1joHYfzH4"
      },
      "source": [
        "df = pd.read_excel('Data_SOC.xlsx')\n",
        "df = pd.DataFrame(df)\n",
        "df1 = pd.DataFrame(columns={'Finance','Sc_Literature','Music/Entertainment'})\n",
        "df1.head()\n",
        "len(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gPJIbMXfzKY",
        "outputId": "4ac1fd11-c584-4096-c53d-ad0bc47305d9"
      },
      "source": [
        "i = 0\n",
        "while( i != len(df)):\n",
        "  content = df['Sc_Literature'][i]\n",
        "  input_ids = tokenizer.encode(content[:100], return_tensors='pt')\n",
        "  output = model.generate(input_ids, max_length = 1000, do_sample = True, top_k = 100, top_p = 0.90)\n",
        "\n",
        "  reference = tokenizer.decode(output[0], skip_special_tokens= True).split()\n",
        "  \n",
        "  len1 = len(content)\n",
        "  len2 = len(reference)\n",
        "  if(len1 >= len2):\n",
        "    hypothesis = content.split()[:len2]\n",
        "  else:\n",
        "    reference = reference[:len1]\n",
        "    hypothesis = content.split()\n",
        "\n",
        "  smoothie = SmoothingFunction().method7\n",
        "  BLEUscore = nltk.translate.bleu_score.corpus_bleu([reference], [hypothesis], smoothing_function=smoothie)\n",
        "  df1.loc[i,'Sc_Literature'] = BLEUscore\n",
        "  print(BLEUscore)\n",
        "  i += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.3331551357294978\n",
            "0.32426610297856595\n",
            "0\n",
            "0\n",
            "0\n",
            "0.34508260127913787\n",
            "0.33477095295745835\n",
            "0\n",
            "0.33591452438333375\n",
            "0.32803107390789743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXMQHu_QfzMw",
        "outputId": "dda31487-b6a0-475e-9054-563973a91ba6"
      },
      "source": [
        "i = 0\n",
        "while( i != len(df)):\n",
        "  content = df['Finance'][i]\n",
        "  input_ids = tokenizer.encode(content[:100], return_tensors='pt')\n",
        "  output = model.generate(input_ids, max_length = 1000, do_sample = True, top_k = 100, top_p = 0.90)\n",
        "\n",
        "  reference = tokenizer.decode(output[0], skip_special_tokens= True).split()\n",
        "  \n",
        "  len1 = len(content)\n",
        "  len2 = len(reference)\n",
        "  if(len1 >= len2):\n",
        "    hypothesis = content.split()[:len2]\n",
        "  else:\n",
        "    reference = reference[:len1]\n",
        "    hypothesis = content.split()\n",
        "\n",
        "  smoothie = SmoothingFunction().method7\n",
        "  BLEUscore = nltk.translate.bleu_score.corpus_bleu([reference], [hypothesis], smoothing_function=smoothie)\n",
        "  df1.loc[i,'Finance'] = BLEUscore\n",
        "  print(BLEUscore)\n",
        "  i += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0.3279765968389653\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0.31816941745854715\n",
            "0\n",
            "0.3399404237368926\n",
            "0.33559210231643416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD6DY0CCfzPI",
        "outputId": "bdfa22ac-bab0-415a-9216-68a7397f43a3"
      },
      "source": [
        "i = 0\n",
        "while( i != len(df)):\n",
        "  content = df['Music/Entertainment'][i]\n",
        "  input_ids = tokenizer.encode(content[:100], return_tensors='pt')\n",
        "  output = model.generate(input_ids, max_length = 1000, do_sample = True, top_k = 100, top_p = 0.90)\n",
        "\n",
        "  reference = tokenizer.decode(output[0], skip_special_tokens= True).split()\n",
        "\n",
        "  len1 = len(content)\n",
        "  len2 = len(reference)\n",
        "  if(len1 >= len2):\n",
        "    hypothesis = content.split()[:len2]\n",
        "  else:\n",
        "    reference = reference[:len1]\n",
        "    hypothesis = content.split()\n",
        "\n",
        "  smoothie = SmoothingFunction().method7\n",
        "  BLEUscore = nltk.translate.bleu_score.corpus_bleu([reference], [hypothesis], smoothing_function=smoothie)\n",
        "  df1.loc[i,'Music/Entertainment'] = BLEUscore\n",
        "  print(BLEUscore)\n",
        "  i += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.32753384709920585\n",
            "0.31816941745854715\n",
            "0.3242509004156918\n",
            "0.32426610297856595\n",
            "0\n",
            "0.334588058295512\n",
            "0.33838179811095664\n",
            "0\n",
            "0\n",
            "0.3269871446268765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7WF5XCFfzRZ"
      },
      "source": [
        "df1.to_csv(r'BLEU_Scores_T5.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAcmC6IjfzTq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLoL0oMffzV4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuCVNM8PfzYM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqYEZXqefzaY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}